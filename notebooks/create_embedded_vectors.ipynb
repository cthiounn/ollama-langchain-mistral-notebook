{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228a124-4243-484e-8cab-a2390f62e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc cp s3/$VAULT_TOP_DIR/Accords/Construction_dataset_public/Dataset_public_accords_teletravail_Dares.parquet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cdea4-16db-48b3-b1b7-521adcfd26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings, OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document, Generation, LLMResult\n",
    "from langchain.llms import Ollama, BaseLLM\n",
    "from langchain.chains import StuffDocumentsChain, RetrievalQA, LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "!python -m spacy download fr_core_news_lg\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\", model_kwargs=model_kwargs,show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec4eed-e5e2-4c41-bc93-5d0f4f50830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"Dataset_public_accords_teletravail_Dares.parquet\"\n",
    "df=pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57cd4e-e790-493d-bb7b-2172b58c5e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a304b-e976-42e4-999a-7e5ae1673540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7485760-cede-4726-b37b-3fc20d9fd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "pipe = nlp.pipe(df.texte_complet_accord, n_process=5,\n",
    "                disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"ner\"])\n",
    "\n",
    "def preprocess_token(token):\n",
    "    if not (token.is_stop or token.is_punct) and token.is_alpha and len(token) >= 3:\n",
    "        return token.lemma_\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def preprocess_text(text_nlp):\n",
    "    text_pretraite_list = [preprocess_token(token) for token in text_nlp if token]\n",
    "    text_pretraite = \" \".join(text_pretraite_list)\n",
    "    return text_pretraite\n",
    "\n",
    "df[\"data_pretraites\"] = [preprocess_text(texte) for texte in pipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fa8c9-675d-4918-bb02-e779a9f6a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=df.data_pretraites[0]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "vectorizer.fit([t])\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "comptages = np.array(vectorizer.transform([t]).sum(0))[0]\n",
    "comptages_voc = list(zip(vocab, comptages))\n",
    "comptages_voc = sorted(comptages_voc, key=lambda x: x[1], reverse=True)\n",
    "comptages_voc = pd.DataFrame(comptages_voc, columns=['mot', 'frequence'])  \n",
    "\n",
    "comptages_voc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c92751-3766-4a23-92b9-7292a01e2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def top5(t):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ff8bf-8bc6-46d0-8afe-180d8510869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma()\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    print(index)\n",
    "    text=df.texte_complet_accord[index]\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    for i,t in enumerate(texts):\n",
    "        embedding=embedder.encode(t)\n",
    "        vector_store.add_documents({\"id\": f\"{index}_{i}\", \"vector\": embedding.tolist(), \"metadata\": {\"text\": f\"{index} : {top5(t)}\"})\n",
    "        del(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897312f5-e324-448f-9ef0-ba5650ce4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.similarity_search(\"télétravail\",2)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
