{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228a124-4243-484e-8cab-a2390f62e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc cp s3/$VAULT_TOP_DIR/Accords/Construction_dataset_public/Dataset_public_accords_teletravail_Dares.parquet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cdea4-16db-48b3-b1b7-521adcfd26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings, OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document, Generation, LLMResult\n",
    "from langchain.llms import Ollama, BaseLLM\n",
    "from langchain.chains import StuffDocumentsChain, RetrievalQA, LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\", model_kwargs=model_kwargs,show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec4eed-e5e2-4c41-bc93-5d0f4f50830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"Dataset_public_accords_teletravail_Dares.parquet\"\n",
    "df=pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7485760-cede-4726-b37b-3fc20d9fd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "pipe = nlp.pipe(df.texte_complet_accord, n_process=5,\n",
    "                disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"ner\"])\n",
    "\n",
    "MOTS_COURANT= {\"chapitre\",\"général\",\"accord\", \"article\",  \"entreprise\", \"relatif\", \"signataire\",\"avenir\", \"soussigné\", \"code\",\"travail\" , \"avenant\"}\n",
    "def preprocess_token(token):\n",
    "    if str(token).lower() not in MOTS_COURANT and not (token.is_stop or token.is_punct) and token.is_alpha and len(token) >= 3:\n",
    "        return token.lemma_\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def preprocess_text(text_nlp):\n",
    "    text_pretraite_list = [preprocess_token(token) for token in text_nlp if token]\n",
    "    text_pretraite = \" \".join(text_pretraite_list)\n",
    "    return text_pretraite\n",
    "\n",
    "#df[\"data_pretraites\"] = [preprocess_text(texte) for texte in pipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fa8c9-675d-4918-bb02-e779a9f6a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_entity(text):\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    for i,t in enumerate(texts):\n",
    "        pipe = nlp.pipe([t.page_content], n_process=5,\n",
    "                    disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"ner\"])\n",
    "        vect = [preprocess_text(texte) for texte in pipe]\n",
    "        print(vect)\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "        vectorizer.fit(vect)\n",
    "        vocab = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        comptages = np.array(vectorizer.transform(vect).sum(0))[0]\n",
    "        comptages_voc = list(zip(vocab, comptages))\n",
    "        comptages_voc = sorted(comptages_voc, key=lambda x: x[1], reverse=True)\n",
    "        comptages_voc = pd.DataFrame(comptages_voc, columns=['mot', 'frequence'])  \n",
    "        \n",
    "        print(comptages_voc.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ff8bf-8bc6-46d0-8afe-180d8510869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(embedding_function=embedder, persist_directory=\"./chroma_db\")\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text=df.texte_complet_accord[index]\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    for i,t in enumerate(texts):\n",
    "        t.metadata[\"id\"]=f\"{index}_{i}\"\n",
    "        t.metadata[\"index\"]=f\"{index}\"\n",
    "        vector_store.add_documents([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a42163-b0d6-45e3-84d7-3e72b6aadf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc cp -r chroma_db s3/$VAULT_TOP_DIR/Accords/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
