{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228a124-4243-484e-8cab-a2390f62e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc cp s3/$VAULT_TOP_DIR/Accords/Construction_dataset_public/Dataset_public_accords_teletravail_Dares.parquet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cdea4-16db-48b3-b1b7-521adcfd26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings, OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document, Generation, LLMResult\n",
    "from langchain.llms import Ollama, BaseLLM\n",
    "from langchain.chains import StuffDocumentsChain, RetrievalQA, LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\", model_kwargs=model_kwargs,show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec4eed-e5e2-4c41-bc93-5d0f4f50830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"Dataset_public_accords_teletravail_Dares.parquet\"\n",
    "df=pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c92751-3766-4a23-92b9-7292a01e2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_in_chunks(lst, chunk_size=5):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ff8bf-8bc6-46d0-8afe-180d8510869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(embedding_function=embedder)\n",
    "for index, row in df.iterrows():\n",
    "    text=df.texte_complet_accord[index]\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    for chunk in iterate_in_chunks(texts):\n",
    "        vector_store.add_documents(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
